# app.py
from typing import List, cast
import io
import numpy as np
import pandas as pd
import streamlit as st

# ====================== åŸºç¡€è®¾ç½® ======================
st.set_page_config(page_title="å”®åæ—¥å¿—åˆ†æ", layout="wide")
st.markdown("# å”®åæ—¥å¿—åˆ†æ")
st.caption("ä¸Šä¼ å¤šä¸ª .txt/.csv æ–‡ä»¶ â†’ åˆå¹¶ä¸ºä¸€ä¸ª DataFrame â†’ ä¾§è¾¹æ é€‰æ‹©è®¾å¤‡ï¼ˆSNï¼‰â†’ æ‹’ä¿æ¡ä»¶åˆ¤æ–­ / ç»´ä¿®é€»è¾‘æ¡ä»¶åˆ¤æ–­ã€‚")

# â€”â€” UI æ ·å¼ï¼šæ ‡é¢˜å¯¹æ¯”ã€æ›´ç´§å‡‘çš„ä¾§è¾¹æ ã€å¡ç‰‡å‘½ä¸­çº¢å­—ã€é¡¶éƒ¨é—´è·æ”¶çª„ â€”â€” 
st.markdown("""
<style>
/* å¼ºåŒ– H1/H2/H3 çš„å±‚çº§å·®å¼‚ + æ”¶çª„é¡¶éƒ¨é—´è· */
h1, .stMarkdown h1 {
  font-size: 2.2rem; font-weight: 800; letter-spacing: .3px;
  margin: 0.2rem 0 0.6rem !important;  /* å‡å°åº•éƒ¨é—´è· */
}
h2, .stMarkdown h2 {
  font-size: 1.6rem; font-weight: 750;
  border-left: 6px solid #4F46E5; padding-left: .55rem;
  margin: 0.6rem 0 0.3rem !important;  /* ç¼©å°ä¸Šä¸‹é—´è· */
}
h3, .stMarkdown h3 {
  font-size: 1.1rem; font-weight: 700;
  text-transform: uppercase; letter-spacing: .08em; color: #374151;
  margin: 0.4rem 0 0.25rem !important;  /* æ›´ç´§å‡‘ */
}

/* é¡¶éƒ¨è¯´æ˜æ–‡å­—é—´è· */
.stMarkdown p {
  margin-top: 0.1rem !important;
  margin-bottom: 0.3rem !important;
}

/* Tab ç»„ä»¶ä¸Šä¸‹é—´è·æ”¶çª„ */
.stTabs [role="tablist"] {
  margin-top: 0rem !important;
  margin-bottom: 0.2rem !important;
}

/* metric æŒ‡æ ‡ä¸Šä¸‹é—´è·æ”¶çª„ */
[data-testid="stMetric"] {
  padding-top: 0.1rem !important;
  padding-bottom: 0.1rem !important;
}

/* ä¾§è¾¹æ ç»„ä»¶ä¹‹é—´æ›´ç´§å‡‘ */
div[data-testid="stSidebar"] .stTextInput,
div[data-testid="stSidebar"] .stNumberInput,
div[data-testid="stSidebar"] .stSelectbox,
div[data-testid="stSidebar"] .stSlider,
div[data-testid="stSidebar"] .stRadio,
div[data-testid="stSidebar"] .stToggle,
div[data-testid="stSidebar"] .stCaptionContainer {
  margin-bottom: .35rem;
}

/* metric æ•°å€¼æ ·å¼ */
[data-testid="stMetricValue"] { font-size: 1.3rem; }
[data-testid="stMetricDelta"] { font-size: .85rem; }

/* â€”â€” å‘½ä¸­/å‰æ–‡/åæ–‡çš„å•å…ƒæ ¼æ ·å¼ â€”â€” */
td.card-hit  { color: #B91C1C !important; font-weight: 900 !important; }  /* å‘½ä¸­è¡Œçº¢å­—+åŠ ç²— */
td.card-pre  { background: #E7F0FF !important; }
td.card-post { background: #E7F8EF !important; }

/* å›ºå®šç¬¬ä¸€åˆ—ï¼ˆâ€œæ ‡è®°â€åˆ—ï¼‰ï¼Œç»§æ‰¿è¡Œæ ·å¼ */
table tbody tr td:first-child {
  position: sticky; left: 0; z-index: 1; background: inherit; color: inherit;
}

/* è¡¨å¤´å°é˜´å½± */
thead tr th { box-shadow: 0 1px 0 rgba(0,0,0,.06); }
            
/* è°ƒæ•´é¡µé¢æ•´ä½“å†…å®¹è·ç¦»é¡¶ç«¯çš„è·ç¦» */
.block-container {
    padding-top: 2.2rem !important;  /* é»˜è®¤å¤§çº¦ 6remï¼Œå¯ä»¥æ”¹æˆæ›´å°çš„å€¼ */
}
            
</style>
""", unsafe_allow_html=True)



# ====================== å¸¸é‡ï¼ˆé»˜è®¤ï¼Œå¯è¢«ä¾§è¾¹æ è¦†ç›–ï¼‰ ======================
DEFAULT_COCA_KEYWORD = "coca"
DEFAULT_DOCA_KEYWORD = "doca"
DEFAULT_PREV_N = 5
DEFAULT_NEXT_N = 1

# ====================== è¯»æ–‡ä»¶ & é¢„å¤„ç† ======================
def _robust_read_csv(b: bytes, filename: str) -> pd.DataFrame:
    """
    è‡ªåŠ¨è§£æï¼šç¼–ç  utf-8â†’gbkâ†’latin-1ï¼Œåˆ†éš”ç¬¦ è‡ªåŠ¨â†’\tâ†’,â†’;â†’|â†’ç©ºç™½
    """
    encodings = ["utf-8", "gbk", "latin-1"]
    seps = [None, "\t", ",", ";", "|", r"\s+"]
    for enc in encodings:
        for sep in seps:
            try:
                df = pd.read_csv(
                    io.BytesIO(b),
                    sep=sep,
                    encoding=enc,
                    engine="python",
                    on_bad_lines="skip",
                )
                df["source_file"] = filename
                return df
            except Exception:
                continue
    # å…œåº•
    df = pd.read_csv(
        io.BytesIO(b),
        sep=r"\s+",
        encoding="latin-1",
        engine="python",
        on_bad_lines="skip",
    )
    df["source_file"] = filename
    return df

@st.cache_data(show_spinner=False)
def read_many(files) -> pd.DataFrame:
    if not files:
        return pd.DataFrame()
    dfs = []
    for f in files:
        df = _robust_read_csv(f.read(), f.name)
        dfs.append(df)
    out = pd.concat(dfs, ignore_index=True)
    out["_row_order"] = np.arange(len(out))
    return out

def infer_column(df: pd.DataFrame, candidates: List[str]) -> str | None:
    cols_lower = {c.lower(): c for c in df.columns}
    for c in candidates:
        if c in cols_lower:
            return cols_lower[c]
    for c in df.columns:
        lc = c.lower()
        if any(k in lc for k in candidates):
            return c
    return None

def normalize_columns(df: pd.DataFrame, col_sn: str | None, col_err: str | None, col_ts: str | None) -> tuple[pd.DataFrame, list[str]]:
    warns = []
    x = df.copy()
    if col_sn:
        x = x.rename(columns={col_sn: "sn"})
    else:
        x["sn"] = "UNKNOWN"
        warns.append("æœªæ‰¾åˆ° sn åˆ—ï¼Œå·²å¡«å……å ä½å€¼ 'UNKNOWN'ã€‚")
    if col_err:
        x = x.rename(columns={col_err: "error"})
    else:
        x["error"] = ""
        warns.append("æœªæ‰¾åˆ° error åˆ—ï¼Œå·²å¡«å……ç©ºå­—ç¬¦ä¸²ã€‚")
    if col_ts:
        x = x.rename(columns={col_ts: "timestamp"})
        try:
            x["timestamp"] = pd.to_datetime(x["timestamp"], errors="coerce")
        except Exception:
            warns.append("timestamp è§£æå¤±è´¥ï¼Œå·²å¿½ç•¥æ—¶é—´æ’åºã€‚")
    x["sn"] = x["sn"].astype(str)
    x["error"] = x["error"].astype(str)
    return x, warns

def demo_data(n_sn=3, rows_per_sn=80, seed=0) -> pd.DataFrame:
    rng = np.random.default_rng(seed)
    sns = [f"SN{1000+i}" for i in range(n_sn)]
    rows = []
    for sn in sns:
        for i in range(rows_per_sn):
            ts = pd.Timestamp("2025-06-01") + pd.to_timedelta(i, unit="m")
            if rng.random() < 0.06:
                err = f"device warning: COCA code={rng.integers(100,999)}"
            else:
                err = f"ok message {rng.integers(1000,9999)}"
            rows.append({"timestamp": ts, "sn": sn, "error": err, "_row_order": i, "source_file": "demo",
                         "data_source": "event" if rng.random()<0.7 else "history"})
    return pd.DataFrame(rows)

# ====================== å®ç”¨å·¥å…· ======================
def _to_int_safe(val) -> int:
    try:
        if pd.isna(val):
            return 0
        if hasattr(val, "item"):
            val = val.item()
        return int(val)
    except Exception:
        try:
            return int(float(val))
        except Exception:
            return 0

def style_card(df_show: pd.DataFrame):
    """
    éœ€è¦åˆ—ï¼š['æ ‡è®°','context_pos',...]
    ä¾æ®â€œå‘½ä¸­/å‰æ–‡/åæ–‡â€æ‰“ classï¼Œå‘½ä¸­è¡Œçº¢å­—ï¼ˆCSS æ§åˆ¶ï¼‰ï¼›å›ºå®šç¬¬ä¸€åˆ—
    """
    classes = []
    for _, row in df_show.iterrows():
        mark = str(row.get("æ ‡è®°", ""))
        try:
            pos = float(row.get("context_pos", 0))
        except Exception:
            pos = 0
        if "å‘½ä¸­" in mark:
            cname = "card-hit"
        elif pos < 0:
            cname = "card-pre"
        else:
            cname = "card-post"
        classes.append([cname] * df_show.shape[1])

    class_df = pd.DataFrame(classes, columns=df_show.columns, index=df_show.index)
    styler = (
        df_show.style
        .set_table_styles([{"selector": "th", "props": [("position","sticky"),("top","0"),("z-index","1")]}])
        .set_td_classes(class_df)
    )
    if hasattr(styler, "hide_index"):
        styler = styler.hide_index()  # type: ignore[attr-defined]
    else:
        try:
            styler = styler.hide(axis="index")
        except Exception:
            pass
    return styler

def sort_group(g: pd.DataFrame) -> pd.DataFrame:
    sort_cols = []
    if "timestamp" in g.columns:
        sort_cols.append("timestamp")
    sort_cols.append("_row_order")
    return g.sort_values(by=sort_cols, kind="stable").reset_index(drop=True)

def extract_cards_for_sn(g: pd.DataFrame, keyword: str, prev_n: int, next_n: int) -> list[pd.DataFrame]:
    """
    æ¯ä¸ªå‘½ä¸­è¡Œç”Ÿæˆä¸€å¼ å¡ç‰‡ï¼ˆç‹¬ç«‹çª—å£ï¼Œä¸åˆå¹¶ï¼‰ï¼Œè¿”å› DataFrame åˆ—è¡¨ã€‚
    åˆ—å«ï¼šis_hit, context_pos, card_id ç­‰ã€‚
    """
    g_sorted = sort_group(g)
    hits = g_sorted.index[g_sorted["error"].str.contains(keyword, case=False, na=False)].tolist()
    cards = []
    n = len(g_sorted)
    for i, hit_idx in enumerate(hits, start=1):
        s = max(0, hit_idx - prev_n)
        e = min(n - 1, hit_idx + next_n)
        block = g_sorted.iloc[s:e+1].copy()
        block["card_id"] = i
        offsets = np.arange(s, e+1) - hit_idx
        block["context_pos"] = offsets
        block["is_hit"] = (block.index == hit_idx).astype(int)
        cards.append(block.reset_index(drop=True))
    return cards

def _first_last_hit_times(cards: list[pd.DataFrame]) -> tuple[str, str]:
    """ä»å¡ç‰‡åˆ—è¡¨æå–é¦–æ¬¡/æœ«æ¬¡å‘½ä¸­æ—¶é—´å­—ç¬¦ä¸²"""
    times = []
    for card_df in cards:
        hit = card_df.loc[card_df["is_hit"] == 1]
        if "timestamp" in hit.columns and not hit.empty and pd.notnull(hit["timestamp"].iloc[0]):
            times.append(hit["timestamp"].iloc[0])
    if times:
        return str(min(times)), str(max(times))
    return "â€”", "â€”"

def _history_long_gap_rows(g: pd.DataFrame, months: int = 6) -> list[tuple[pd.Series, pd.Series, pd.Timedelta]]:
    """
    æ£€æŸ¥ data_source=='history' çš„è®°å½•æ˜¯å¦å­˜åœ¨ç›¸é‚»ä¸¤æ¡æ—¶é—´å·® > monthsï¼ˆæŒ‰ 30*months å¤©è¿‘ä¼¼ï¼‰ã€‚
    """
    if "data_source" not in g.columns:
        return []

    h = g[g["data_source"].astype(str).str.lower() == "history"].copy()
    if h.empty:
        return []

    # ç»Ÿä¸€æ—¶é—´åˆ—ï¼šä¼˜å…ˆ 'timestamp'ï¼Œå¦åˆ™ 'time'
    if "timestamp" in h.columns:
        tcol = "timestamp"
    elif "time" in h.columns:
        tcol = "time"
    else:
        return []

    h["_ts"] = pd.to_datetime(h[tcol], errors="coerce")
    h = h.dropna(subset=["_ts"]).sort_values(
        by=["_ts", "_row_order"] if "_row_order" in h.columns else ["_ts"]
    ).reset_index(drop=True)

    if len(h) < 2:
        return []

    threshold = pd.Timedelta(days=30 * months)  # è¿‘ä¼¼æœˆä»½
    res: list[tuple[pd.Series, pd.Series, pd.Timedelta]] = []

    for i in range(1, len(h)):
        row_prev = cast(pd.Series, h.iloc[i - 1, :])
        row_next = cast(pd.Series, h.iloc[i, :])
        t0 = row_prev["_ts"]
        t1 = row_next["_ts"]
        delta: pd.Timedelta = t1 - t0  # type: ignore[assignment]
        if pd.isna(delta):
            continue
        if delta > threshold:
            res.append((row_prev, row_next, delta))

    return res

# ====================== ä¾§è¾¹æ ï¼šä¸Šä¼  & è®¾å¤‡é€‰æ‹© & å‚æ•° ======================
with st.sidebar:
    st.header("ğŸ“¥ ä¸Šä¼ ")
    files = st.file_uploader(
        "ä¸Šä¼ å¤šä¸ª .txt / .csv æ–‡ä»¶ï¼ˆå¯å¤šé€‰ï¼‰",
        type=["txt", "csv"],
        accept_multiple_files=True,
    )
    st.markdown("---")
    demo = st.toggle("ä½¿ç”¨æ¼”ç¤ºæ•°æ®ï¼ˆå¿½ç•¥ä¸Šä¼ ï¼‰", value=False)

# è¯»å–æ•°æ®
if demo:
    raw_df = demo_data()
else:
    raw_df = read_many(files)

if raw_df.empty:
    st.info("è¯·åœ¨å·¦ä¾§ä¸Šä¼ æ–‡ä»¶ï¼Œæˆ–å¼€å¯æ¼”ç¤ºæ•°æ®ã€‚")
    st.stop()

# è‡ªåŠ¨è¯†åˆ«åˆ—ï¼ˆsn / error / timeâ†’timestampï¼‰
auto_sn = infer_column(raw_df, ["sn"])
auto_err = infer_column(raw_df, ["error", "err", "errmsg", "message", "msg"])
auto_ts = infer_column(raw_df, ["timestamp", "time", "datetime", "date", "ts"])
df, warns = normalize_columns(raw_df, auto_sn, auto_err, auto_ts)
if warns:
    for w in warns:
        st.warning(w)

# ä¾§è¾¹æ ï¼šSN é€‰æ‹© + åˆ¤æ–­å‚æ•°ï¼ˆæ›´ç´§å‡‘ï¼‰
with st.sidebar:
    st.header("ğŸ”Œ é€‰æ‹©è®¾å¤‡ï¼ˆSNï¼‰")
    all_sns = sorted(df["sn"].astype(str).unique().tolist())
    q = st.text_input("æœç´¢ SNï¼ˆæ”¯æŒæ¨¡ç³ŠåŒ¹é…ï¼‰", value="", placeholder="è¾“å…¥ SN å…³é”®å­—â€¦")
    filtered = [s for s in all_sns if q.lower() in s.lower()] if q else all_sns
    if q and not filtered:
        st.info("æœªåŒ¹é…åˆ° SNï¼Œå·²æ˜¾ç¤ºå…¨éƒ¨ã€‚")
        filtered = all_sns
    sn_pick = st.radio("ç‚¹å‡» SN æŸ¥çœ‹é¡µé¢ï¼š", filtered, index=0, label_visibility="visible")

    st.markdown("---")
    st.header("âš™ï¸ åˆ¤æ–­å‚æ•°")

    # å¸¸ç”¨ï¼šå…³é”®è¯ + History é˜ˆå€¼ï¼ˆæœˆï¼‰
    cola, colb = st.columns(2)
    with cola:
        coca_kw = st.text_input("COCA å…³é”®å­—", value=DEFAULT_COCA_KEYWORD, placeholder="å¦‚ï¼šcoca", key="kw_coca")
    with colb:
        doca_kw = st.text_input("DOCA å…³é”®å­—", value=DEFAULT_DOCA_KEYWORD, placeholder="å¦‚ï¼šdoca", key="kw_doca")

    history_months = st.number_input(
        "History ç›¸é‚»é—´éš”é˜ˆå€¼ï¼ˆæœˆï¼‰",
        min_value=1, max_value=36, value=6, step=1,
        help="ç”¨äºâ€œHistory æç½®æ£€æŸ¥â€ï¼Œç›¸é‚»ä¸¤æ¡è¶…è¿‡è¯¥æœˆæ•°åˆ™æç¤º"
    )
    st.session_state["history_months"] = int(history_months)

    # é«˜çº§è®¾ç½®ï¼šä¸Šä¸‹æ–‡çª—å£è¡Œæ•°
    with st.expander("é«˜çº§è®¾ç½®ï¼šä¸Šä¸‹æ–‡çª—å£è¡Œæ•°", expanded=False):
        ca1, ca2, da1, da2 = st.columns(4)
        with ca1:
            coca_prev = st.number_input("COCA å‰ç½®è¡Œ", min_value=0, max_value=100, value=DEFAULT_PREV_N, step=1, key="prev_coca")
        with ca2:
            coca_next = st.number_input("COCA åç½®è¡Œ", min_value=0, max_value=100, value=DEFAULT_NEXT_N, step=1, key="next_coca")
        with da1:
            doca_prev = st.number_input("DOCA å‰ç½®è¡Œ", min_value=0, max_value=100, value=DEFAULT_PREV_N, step=1, key="prev_doca")
        with da2:
            doca_next = st.number_input("DOCA åç½®è¡Œ", min_value=0, max_value=100, value=DEFAULT_NEXT_N, step=1, key="next_doca")

# ====================== å• SN é¡µé¢ï¼ˆä¸¤çº§ Tabï¼‰ ======================
g = df[df["sn"] == sn_pick].copy()
st.markdown(f"## {sn_pick}")
st.markdown("### åˆ¤æ–­ç»“æœ")

# é¡¶å±‚åˆ†ç»„ï¼šæ‹’ä¿ & ç»´ä¿® & åŸå§‹æ•°æ®
top_tabs = st.tabs(["æ‹’ä¿æ¡ä»¶åˆ¤æ–­", "ç»´ä¿®é€»è¾‘æ¡ä»¶åˆ¤æ–­", "åŸå§‹æ•°æ®"])

# ---------- æ‹’ä¿æ¡ä»¶åˆ¤æ–­ï¼ˆCOCA / DOCA / POV-PUV / Historyï¼‰ ----------
with top_tabs[0]:
    rej_tabs = st.tabs(["COCA", "DOCA", "POV/PUV æ¬¡æ•°", "History æç½®æ£€æŸ¥"])

    # ---------- COCA ----------
    with rej_tabs[0]:
        st.markdown("### COCA åˆ¤æ–­ç»“æœ")
        coca_cards = extract_cards_for_sn(g, keyword=coca_kw, prev_n=int(coca_prev), next_n=int(coca_next))
        first_t, last_t = _first_last_hit_times(coca_cards)

        c1, c2, c3 = st.columns(3)
        c1.metric("COCA äº‹ä»¶æ•°", len(coca_cards))
        c2.metric("é¦–æ¬¡å‘½ä¸­æ—¶é—´", first_t)
        c3.metric("æœ«æ¬¡å‘½ä¸­æ—¶é—´", last_t)

        num_events = len(coca_cards)
        state_key = f"card_idx_{sn_pick}_COCA"
        if state_key not in st.session_state:
            st.session_state[state_key] = 1

        nav_l, nav_c, nav_r = st.columns([1, 3, 1])
        with nav_l:
            prev_disabled = st.session_state[state_key] <= 1 or num_events == 0
            if st.button("â¬…ï¸ ä¸Šä¸€äº‹ä»¶", disabled=prev_disabled, key=f"prev_{state_key}"):
                st.session_state[state_key] = max(1, st.session_state[state_key] - 1)
        with nav_c:
            if num_events > 0:
                new_idx = st.slider("è·³è½¬äº‹ä»¶åºå·", 1, num_events, st.session_state[state_key], key=f"slider_{state_key}")
                if new_idx != st.session_state[state_key]:
                    st.session_state[state_key] = new_idx
            else:
                st.write("ï¼ˆæ— äº‹ä»¶å¯è·³è½¬ï¼‰")
        with nav_r:
            next_disabled = st.session_state[state_key] >= num_events or num_events == 0
            if st.button("ä¸‹ä¸€äº‹ä»¶ â¡ï¸", disabled=next_disabled, key=f"next_{state_key}"):
                st.session_state[state_key] = min(num_events, st.session_state[state_key] + 1)

        if num_events > 0:
            all_cards_df = pd.concat(
                [c.drop(columns=["is_hit"], errors="ignore").assign(card_id=_to_int_safe(c["card_id"].iat[0])) for c in coca_cards],
                ignore_index=True,
            )
            st.download_button(
                "â¬‡ï¸ ä¸‹è½½æœ¬è®¾å¤‡å…¨éƒ¨ COCA äº‹ä»¶ï¼ˆCSVï¼‰",
                data=all_cards_df.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{sn_pick}_coca_events_all.csv",
                mime="text/csv",
                key=f"dl_all_coca_{sn_pick}"
            )

        if not coca_cards:
            st.info("æœªå‘ç°åŒ…å« COCA çš„è¡Œã€‚")
        else:
            st.caption(f"å…±å‘ç° **{num_events}** ä¸ª COCA äº‹ä»¶ã€‚ä½¿ç”¨ä¸Šæ–¹æ§ä»¶å¿«é€Ÿè·³è½¬ã€‚")
            current_card_id = st.session_state[state_key] if num_events > 0 else None
            for card_df in coca_cards:
                card_id = _to_int_safe(card_df["card_id"].iat[0])
                hit_row = card_df.loc[card_df["is_hit"] == 1]
                hit_time = hit_row["timestamp"].iloc[0] if "timestamp" in hit_row.columns and not hit_row.empty else None
                hit_msg = hit_row["error"].iloc[0] if not hit_row.empty else ""
                title = f"ğŸ§© äº‹ä»¶ #{card_id}"
                subtitle = f"å‘½ä¸­: {str(hit_time) if pd.notnull(hit_time) else 'æ— æ—¶é—´'} ï½œ {hit_msg}"
                expanded_flag = (card_id == current_card_id)
                with st.expander(f"{title} ï½œ {subtitle}", expanded=expanded_flag):
                    # â€”â€” å°† COCA å¡ç‰‡é‡Œæ¸²æŸ“æ•°æ®è¡¨æ ¼çš„éƒ¨åˆ†æ›¿æ¢ä¸ºä¸‹é¢è¿™æ®µï¼ˆä¿ç•™ä½ åŸæœ‰çš„ show æ„å»ºé€»è¾‘ä¸ä¸‹è½½æŒ‰é’®ï¼‰â€”â€”
                    display_cols = [c for c in ["timestamp", "sn", "error", "source_file", "_row_order", "context_pos"] if c in card_df.columns]
                    extra_cols = [c for c in card_df.columns if c not in display_cols + ["is_hit", "card_id"]]
                    show = card_df[display_cols + extra_cols].copy()
                    show.insert(0, "æ ‡è®°", np.where(card_df["is_hit"] == 1, "â˜… å‘½ä¸­", np.where(card_df["context_pos"] < 0, "â†‘ å‰æ–‡", "â†“ åæ–‡")))

                    # ä»…ä½¿ç”¨ Streamlit å†…ç½®å±•ç¤ºï¼šst.dataframe + pandas Stylerï¼ˆå‘½ä¸­/åŒ…å« COCA çš„ error å­—ä½“çº¢è‰²ï¼‰
                    _coca_mask = card_df.get("error", pd.Series([], dtype=str)).str.contains(coca_kw, case=False, na=False)

                    def _style_error_col(col: pd.Series):
                        if col.name != "error":
                            return [""] * len(col)
                        return ["color: #B91C1C; font-weight: 900" if bool(m) else "" for m in _coca_mask]

                    styler = show.style.apply(_style_error_col, axis=0)
                    try:
                        styler = styler.hide_index()  # type: ignore[attr-defined]
                    except Exception:
                        try:
                            styler = styler.hide(axis="index")
                        except Exception:
                            pass

                    st.dataframe(styler, use_container_width=True, height=300)
                    csv_card = card_df.drop(columns=["is_hit"], errors="ignore").to_csv(index=False).encode("utf-8-sig")
                    st.download_button(
                        f"ä¸‹è½½äº‹ä»¶ #{card_id}ï¼ˆCSVï¼‰",
                        data=csv_card,
                        file_name=f"{sn_pick}_coca_event_{card_id}.csv",
                        mime="text/csv",
                        key=f"dl_coca_{sn_pick}_{card_id}"
                    )

    # ---------- DOCA ----------
    with rej_tabs[1]:
        st.markdown("### DOCA åˆ¤æ–­ç»“æœ")
        doca_cards = extract_cards_for_sn(g, keyword=doca_kw, prev_n=int(doca_prev), next_n=int(doca_next))
        first_t, last_t = _first_last_hit_times(doca_cards)

        c1, c2, c3 = st.columns(3)
        c1.metric("DOCA äº‹ä»¶æ•°", len(doca_cards))
        c2.metric("é¦–æ¬¡å‘½ä¸­æ—¶é—´", first_t)
        c3.metric("æœ«æ¬¡å‘½ä¸­æ—¶é—´", last_t)

        num_events = len(doca_cards)
        state_key = f"card_idx_{sn_pick}_DOCA"
        if state_key not in st.session_state:
            st.session_state[state_key] = 1

        nav_l, nav_c, nav_r = st.columns([1, 3, 1])
        with nav_l:
            prev_disabled = st.session_state[state_key] <= 1 or num_events == 0
            if st.button("â¬…ï¸ ä¸Šä¸€äº‹ä»¶", disabled=prev_disabled, key=f"prev_{state_key}"):
                st.session_state[state_key] = max(1, st.session_state[state_key] - 1)
        with nav_c:
            if num_events > 0:
                new_idx = st.slider("è·³è½¬äº‹ä»¶åºå·", 1, num_events, st.session_state[state_key], key=f"slider_{state_key}")
                if new_idx != st.session_state[state_key]:
                    st.session_state[state_key] = new_idx
            else:
                st.write("ï¼ˆæ— äº‹ä»¶å¯è·³è½¬ï¼‰")
        with nav_r:
            next_disabled = st.session_state[state_key] >= num_events or num_events == 0
            if st.button("ä¸‹ä¸€äº‹ä»¶ â¡ï¸", disabled=next_disabled, key=f"next_{state_key}"):
                st.session_state[state_key] = min(num_events, st.session_state[state_key] + 1)

        if num_events > 0:
            all_cards_df = pd.concat(
                [c.drop(columns=["is_hit"], errors="ignore").assign(card_id=_to_int_safe(c["card_id"].iat[0])) for c in doca_cards],
                ignore_index=True,
            )
            st.download_button(
                "â¬‡ï¸ ä¸‹è½½æœ¬è®¾å¤‡å…¨éƒ¨ DOCA äº‹ä»¶ï¼ˆCSVï¼‰",
                data=all_cards_df.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{sn_pick}_doca_events_all.csv",
                mime="text/csv",
                key=f"dl_all_doca_{sn_pick}"
            )

        if not doca_cards:
            st.info("æœªå‘ç°åŒ…å« DOCA çš„è¡Œã€‚")
        else:
            st.caption(f"å…±å‘ç° **{num_events}** ä¸ª DOCA äº‹ä»¶ã€‚ä½¿ç”¨ä¸Šæ–¹æ§ä»¶å¿«é€Ÿè·³è½¬ã€‚")
            current_card_id = st.session_state[state_key] if num_events > 0 else None
            for card_df in doca_cards:
                card_id = _to_int_safe(card_df["card_id"].iat[0])
                hit_row = card_df.loc[card_df["is_hit"] == 1]
                hit_time = hit_row["timestamp"].iloc[0] if "timestamp" in hit_row.columns and not hit_row.empty else None
                hit_msg = hit_row["error"].iloc[0] if not hit_row.empty else ""
                title = f"ğŸ§© äº‹ä»¶ #{card_id}"
                subtitle = f"å‘½ä¸­: {str(hit_time) if pd.notnull(hit_time) else 'æ— æ—¶é—´'} ï½œ {hit_msg}"
                expanded_flag = (card_id == current_card_id)
                with st.expander(f"{title} ï½œ {subtitle}", expanded=expanded_flag):
                    display_cols = [c for c in ["timestamp", "sn", "error", "source_file", "_row_order", "context_pos"] if c in card_df.columns]
                    extra_cols = [c for c in card_df.columns if c not in display_cols + ["is_hit", "card_id"]]
                    show = card_df[display_cols + extra_cols].copy()
                    show.insert(0, "æ ‡è®°", np.where(card_df["is_hit"] == 1, "â˜… å‘½ä¸­", np.where(card_df["context_pos"] < 0, "â†‘ å‰æ–‡", "â†“ åæ–‡")))
                    try:
                        styler = style_card(show)
                        st.markdown(styler.to_html(), unsafe_allow_html=True)
                    except Exception:
                        st.dataframe(show, use_container_width=True, height=300)
                    csv_card = card_df.drop(columns=["is_hit"], errors="ignore").to_csv(index=False).encode("utf-8-sig")
                    st.download_button(
                        f"ä¸‹è½½äº‹ä»¶ #{card_id}ï¼ˆCSVï¼‰",
                        data=csv_card,
                        file_name=f"{sn_pick}_doca_event_{card_id}.csv",
                        mime="text/csv",
                        key=f"dl_doca_{sn_pick}_{card_id}"
                    )

    # ---------- POV / PUV æ¬¡æ•° ----------
    with rej_tabs[2]:
        st.markdown("### POV / PUV æ¬¡æ•°")
        err_col = "error" if "error" in g.columns else None
        if not err_col:
            st.info("æœªæ‰¾åˆ° error åˆ—ã€‚")
        else:
            pov_mask = g[err_col].str.contains("pov", case=False, na=False)
            puv_mask = g[err_col].str.contains("puv", case=False, na=False)
            pov_rows = g[pov_mask].copy()
            puv_rows = g[puv_mask].copy()

            colA, colB = st.columns(2)
            colA.metric("POV æ¬¡æ•°", len(pov_rows))
            colB.metric("PUV æ¬¡æ•°", len(puv_rows))

            st.subheader("POV å‘½ä¸­è¡Œ")
            st.dataframe(pov_rows, use_container_width=True, height=260)
            st.download_button(
                "ä¸‹è½½ POV å‘½ä¸­è¡Œï¼ˆCSVï¼‰",
                data=pov_rows.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{sn_pick}_POV_rows.csv",
                mime="text/csv",
                key=f"dl_pov_{sn_pick}"
            )

            st.subheader("PUV å‘½ä¸­è¡Œ")
            st.dataframe(puv_rows, use_container_width=True, height=260)
            st.download_button(
                "ä¸‹è½½ PUV å‘½ä¸­è¡Œï¼ˆCSVï¼‰",
                data=puv_rows.to_csv(index=False).encode("utf-8-sig"),
                file_name=f"{sn_pick}_PUV_rows.csv",
                mime="text/csv",
                key=f"dl_puv_{sn_pick}"
            )

    # ---------- History æç½®æ£€æŸ¥ ----------
    with rej_tabs[3]:
        hm = int(st.session_state.get("history_months", 6))
        st.markdown(f"### History æç½®æ£€æŸ¥ï¼ˆ> {hm} ä¸ªæœˆï¼‰")
        gaps = _history_long_gap_rows(g, months=hm)
        if not gaps:
            st.success("æœªå‘ç°è¶…è¿‡é˜ˆå€¼çš„ history ç›¸é‚»è®°å½•é—´éš”ã€‚")
        else:
            st.warning(f"å‘ç° **{len(gaps)}** å¤„è¶…è¿‡ {hm} ä¸ªæœˆçš„é—´éš”ï¼š")
            for idx, (row0, row1, delta) in enumerate(gaps, start=1):
                st.markdown(f"**é—´éš” #{idx}**ï¼š{delta}  ï¼ˆ{row0.get('timestamp', 'â€”')} â†’ {row1.get('timestamp', 'â€”')}ï¼‰")
                show0 = pd.DataFrame([row0])
                show1 = pd.DataFrame([row1])
                st.write("ä¸Šä¸€æ¡è®°å½•ï¼š")
                st.dataframe(show0, use_container_width=True, height=120)
                st.write("ä¸‹ä¸€æ¡è®°å½•ï¼š")
                st.dataframe(show1, use_container_width=True, height=120)

# ---------- ç»´ä¿®é€»è¾‘æ¡ä»¶åˆ¤æ–­ï¼ˆé¢„ç•™ 3 ä¸ª Tabï¼‰ ----------
with top_tabs[1]:
    svc_tabs = st.tabs(["å……é«˜æ”¾ä½ï¼ˆé¢„ç•™ï¼‰", "é‡‡æ ·å¼‚å¸¸ï¼ˆé¢„ç•™ï¼‰", "æ˜¯å¦å‡è¡¡ï¼ˆé¢„ç•™ï¼‰"])

    with svc_tabs[0]:
        st.markdown("### å……é«˜æ”¾ä½ï¼ˆé¢„ç•™ï¼‰")
        st.info("ç»´ä¿®é€»è¾‘ Â· å……é«˜æ”¾ä½ï¼šç®—æ³•/æŒ‡æ ‡å¾…æ¥å…¥ã€‚æ­¤å¤„å…ˆå ä½ã€‚")

    with svc_tabs[1]:
        st.markdown("### é‡‡æ ·å¼‚å¸¸ï¼ˆé¢„ç•™ï¼‰")
        st.info("ç»´ä¿®é€»è¾‘ Â· é‡‡æ ·å¼‚å¸¸ï¼šç®—æ³•/æŒ‡æ ‡å¾…æ¥å…¥ã€‚æ­¤å¤„å…ˆå ä½ã€‚")

    with svc_tabs[2]:
        st.markdown("### æ˜¯å¦å‡è¡¡ï¼ˆé¢„ç•™ï¼‰")
        st.info("ç»´ä¿®é€»è¾‘ Â· æ˜¯å¦å‡è¡¡ï¼šç®—æ³•/æŒ‡æ ‡å¾…æ¥å…¥ã€‚æ­¤å¤„å…ˆå ä½ã€‚")

# ---------- åŸå§‹æ•°æ® ----------
with top_tabs[2]:
    st.markdown("### åŸå§‹æ•°æ®ï¼ˆå‰ 200 è¡Œï¼‰")
    st.dataframe(g.head(200), use_container_width=True, height=320)
